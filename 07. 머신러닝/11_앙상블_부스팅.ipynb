{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "부스팅(Boosting)이란 단순하고 약한 학습기(Weak Learner)들를 결합해서 보다 정확하고 강력한 학습기(Strong Learner)를 만드는 방식.  \n",
    "정확도가 낮은 하나의 모델을 만들어 학습 시킨뒤, 그 모델의 예측 오류는 두 번째 모델이 보완한다. 이 두 모델을 합치면 처음보다는 정확한 모델이 만들어 진다. 합쳐진 모델의 예측 오류는 다음 모델에서 보완하여 계속 더하는 과정을 반복한다.\n",
    "\n",
    "- 약한 학습기들은 앞 학습기가 만든 오류를 줄이는 방향으로 학습한다.\n",
    "- gradient boosting\n",
    "    - 처음 모델은 y를 예측 두번째 부터는 앞 모델이 만든 오류를 예측 그것을 앞 모델에 업데이트하면 오류를 줄일 수 있다.\n",
    "    - 그 오류를 update할 때 뺄까 더할까를 gradient descent 방법을 쓴다. 미분해서 나오는 값의 음수를 취해서 적용. \n",
    "    - 학습률을 작게하면 update가 조금씩 크면 많이 하게 된다. 그래서 크게하면 학습데이터에 너무 맞아 과대적합 될 수 있다.\n",
    "\n",
    "## GradientBoosting\n",
    "- 개별 모델로 Decision Tree 를 사용한다. \n",
    "- depth가 깊지 않은 트리를 많이 연결해서 이전 트리의 오차를 보정해 나가는 방식으로 실행한다.\n",
    "- 오차를 보정할 때 경사하강법(Gradient descent)을 사용한다.\n",
    "- 얕은 트리를 많이 연결하여 각각의 트리가 데이터의 일부에 대해 예측을 잘 수행하도록 하고 그런 트리들이 모여 전체 성능을 높이는 것이 기본 아이디어.\n",
    "- 분류와 회귀 둘다 지원하는 모델 (GradientBoostingClassification, GrandientBoostingRegressor)\n",
    "- 훈련시간이 많이 걸리고, 트리기반 모델의 특성상 희소한 고차원 데이터에서는 성능이 않좋은 단점이 있다.\n",
    "\n",
    "### 주요 파라미터\n",
    "- Decision Tree 의 가지치기 관련 매개변수\n",
    "    - 각각의 tree가 복잡한 모델이 되지 않도록 한다. \n",
    "- learning rate\n",
    "    - 이전 tree의 오차를 얼마나 강하게 보정할 것인지 제어하는 값. \n",
    "    - 값이 크면 보정을 강하게 하여 복잡한 모델을 만든다. 학습데이터의 정확도는 올라가지만 과대적합이 날 수있다. \n",
    "    - 값을 작게 잡으면 보정을 약하게 하여 모델의 복잡도를 줄인다. 과대적합을 줄일 수 있지만 성능 자체가 낮아질 수있다.\n",
    "    - 기본값 : 0.1\n",
    "- n_estimators\n",
    "    - tree의 개수 지정. 많을 수록 복잡한 모델이 된다.\n",
    "- n_iter_no_change, validation_fraction\n",
    "    - validation_fraction에 지정한 비율만큼 n_iter_no_change에 지정한 반복 횟수동안 검증점수가 좋아 지지 않으면 훈련을 조기 종료한다.\n",
    "\n",
    "- 보통 max_depth를 낮춰 개별 트리의 복잡도를 낮춘다. (5가 넘지 않게) 그리고 n_estimators를 가용시간, 메모리 한도에 맞춘뒤 적절한 learning_rate을 찾는다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426,), (143,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data['data'], data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=1)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = gb.predict(X_train)\n",
    "pred_test = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.958041958041958)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, pred_train), accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 중요도\n",
    "import pandas as pd\n",
    "fi = gb.feature_importances_\n",
    "fi_s = pd.Series(fi, index=data['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst radius               0.383871\n",
       "worst concave points       0.285990\n",
       "worst perimeter            0.130654\n",
       "mean concave points        0.046544\n",
       "worst area                 0.042472\n",
       "worst texture              0.041187\n",
       "worst concavity            0.012790\n",
       "area error                 0.010906\n",
       "mean texture               0.009120\n",
       "mean concavity             0.007964\n",
       "radius error               0.004788\n",
       "concavity error            0.003404\n",
       "worst fractal dimension    0.002838\n",
       "worst symmetry             0.002546\n",
       "mean area                  0.002540\n",
       "fractal dimension error    0.002532\n",
       "mean compactness           0.001572\n",
       "compactness error          0.001384\n",
       "mean perimeter             0.001381\n",
       "smoothness error           0.001340\n",
       "symmetry error             0.001267\n",
       "perimeter error            0.000813\n",
       "mean radius                0.000656\n",
       "mean fractal dimension     0.000625\n",
       "texture error              0.000575\n",
       "worst compactness          0.000097\n",
       "worst smoothness           0.000066\n",
       "mean symmetry              0.000039\n",
       "mean smoothness            0.000032\n",
       "concave points error       0.000008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_s.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV 이용해 최적의 하이퍼파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "param = {\n",
    "    'n_estimators':[100,200,300,400,500], # tree개수(dafault)\n",
    "    'learning_rate':[0.001,0.01,0.1], # 학습률\n",
    "    'max_depth':range(1,5),\n",
    "    'subsample':[0.5,0.7,1], # 학습시킬 sample의 비율\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "gs = GridSearchCV(gb,\n",
    "                 param_grid=param,\n",
    "                 cv=3,\n",
    "                 scoring='accuracy',\n",
    "                 n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=1),\n",
       "             n_jobs=2,\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                         'max_depth': range(1, 5),\n",
       "                         'n_estimators': [100, 200, 300, 400, 500],\n",
       "                         'subsample': [0.5, 0.7, 1]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0528667 , 0.06234638, 0.07263168, 0.10459328, 0.12359436,\n",
       "        0.14148116, 0.15565157, 0.1844782 , 0.21130149, 0.22048426,\n",
       "        0.26485912, 0.29168185, 0.26217548, 0.30464435, 0.36251688,\n",
       "        0.08467237, 0.09745534, 0.1175979 , 0.15388838, 0.19353644,\n",
       "        0.2357498 , 0.22575482, 0.29557411, 0.36128283, 0.31714296,\n",
       "        0.38812351, 0.49388576, 0.38210003, 0.48848971, 0.59628344,\n",
       "        0.10309855, 0.13107212, 0.16149028, 0.21066101, 0.26272527,\n",
       "        0.31899476, 0.30840262, 0.3960561 , 0.50631261, 0.42531562,\n",
       "        0.52637378, 0.70412302, 0.54770764, 0.68476033, 0.84187969,\n",
       "        0.13351043, 0.18686597, 0.21489811, 0.26454528, 0.33558559,\n",
       "        0.40089973, 0.39072339, 0.50183503, 0.627129  , 0.52904495,\n",
       "        0.68969154, 0.80880698, 0.66335265, 0.86460861, 1.06701907,\n",
       "        0.05283825, 0.06156484, 0.07399281, 0.10279854, 0.12396193,\n",
       "        0.14248967, 0.16617497, 0.18526912, 0.21408351, 0.22118815,\n",
       "        0.26850351, 0.28930815, 0.27185996, 0.31475536, 0.35434977,\n",
       "        0.07430593, 0.09331115, 0.11399794, 0.1566654 , 0.19733349,\n",
       "        0.23347505, 0.23297946, 0.28465406, 0.34062974, 0.30805238,\n",
       "        0.39000201, 0.46517046, 0.40156889, 0.47644043, 0.61283239,\n",
       "        0.10139783, 0.12896729, 0.16425689, 0.19954483, 0.25509365,\n",
       "        0.32348315, 0.3013552 , 0.3983264 , 0.48119879, 0.40706611,\n",
       "        0.51914263, 0.66894166, 0.51235676, 0.65015626, 0.83923038,\n",
       "        0.13399498, 0.16106542, 0.21862769, 0.25598478, 0.33483092,\n",
       "        0.42720095, 0.41283417, 0.49157238, 0.63067667, 0.51178145,\n",
       "        0.65850258, 0.87478232, 0.64250612, 0.80688143, 1.06920791,\n",
       "        0.06252638, 0.06526748, 0.07529163, 0.10625672, 0.12515831,\n",
       "        0.13802322, 0.15435394, 0.18319416, 0.20728946, 0.20584146,\n",
       "        0.24514167, 0.28734152, 0.25725563, 0.30539997, 0.34772929,\n",
       "        0.07644335, 0.0976185 , 0.11954761, 0.15668686, 0.19352094,\n",
       "        0.23051167, 0.22638853, 0.29404449, 0.35173575, 0.30239193,\n",
       "        0.37586212, 0.46394555, 0.41239421, 0.47381401, 0.57407689,\n",
       "        0.09803629, 0.1251289 , 0.16017191, 0.20012728, 0.25163953,\n",
       "        0.33395314, 0.29626743, 0.38985435, 0.48484937, 0.39922118,\n",
       "        0.54453588, 0.67167346, 0.49275263, 0.62897984, 0.8083245 ,\n",
       "        0.12911026, 0.15912278, 0.21050318, 0.24847674, 0.32084052,\n",
       "        0.44314488, 0.37881049, 0.48459093, 0.66660682, 0.52812576,\n",
       "        0.69678164, 0.87524764, 0.65800587, 0.84506067, 1.12719941]),\n",
       " 'std_fit_time': array([1.07913492e-05, 4.06374768e-04, 1.16521988e-03, 9.97125160e-04,\n",
       "        7.18994366e-04, 2.46516866e-03, 7.34456498e-04, 2.15898949e-03,\n",
       "        7.21218346e-03, 1.57118661e-03, 1.32967619e-02, 9.32156599e-03,\n",
       "        1.65900438e-03, 1.25843420e-03, 8.01266859e-03, 7.73092323e-03,\n",
       "        1.81220209e-03, 8.64494772e-04, 2.97016743e-03, 4.67908693e-03,\n",
       "        2.94575507e-03, 9.58041470e-04, 3.09930848e-03, 4.42251718e-03,\n",
       "        7.11249015e-03, 3.59722941e-03, 3.34412658e-03, 6.51161728e-04,\n",
       "        7.55400479e-03, 8.85677568e-03, 4.36876812e-03, 3.85525950e-03,\n",
       "        1.19472281e-03, 8.20961864e-03, 1.72156180e-03, 6.54252337e-03,\n",
       "        2.55638484e-04, 3.87128975e-03, 1.91386739e-02, 8.17955914e-03,\n",
       "        9.54017570e-03, 1.72308992e-02, 2.08009173e-02, 2.00672498e-02,\n",
       "        2.17473257e-02, 2.98566339e-03, 1.09536373e-02, 3.01751046e-03,\n",
       "        5.15114153e-04, 3.77037858e-04, 1.82204151e-02, 1.77706801e-03,\n",
       "        1.05314008e-02, 2.86791625e-02, 1.00656067e-02, 2.32933723e-02,\n",
       "        3.36058500e-02, 1.17612685e-02, 2.69295634e-03, 2.99572940e-02,\n",
       "        1.06858878e-03, 4.45766763e-04, 2.84243539e-03, 8.71711805e-04,\n",
       "        9.95452417e-04, 8.64238925e-04, 2.06179421e-03, 1.87268289e-03,\n",
       "        4.19621271e-03, 5.14543586e-03, 7.49635250e-03, 3.72626357e-03,\n",
       "        2.21790890e-03, 5.22316381e-03, 9.69004932e-03, 5.24388872e-04,\n",
       "        1.96045827e-03, 1.52951171e-04, 3.94104380e-03, 3.86689816e-03,\n",
       "        5.06583880e-03, 1.89596719e-03, 6.08729041e-03, 1.26031246e-03,\n",
       "        6.40091432e-03, 7.91485595e-03, 5.98907153e-03, 3.79578964e-03,\n",
       "        8.94520208e-03, 1.04775809e-02, 3.75927435e-03, 3.38294578e-03,\n",
       "        5.55675441e-03, 1.10626858e-03, 1.78054602e-03, 3.31389467e-03,\n",
       "        2.23027728e-03, 1.50914278e-02, 6.64109688e-03, 4.19210499e-03,\n",
       "        1.69295323e-02, 8.29636182e-03, 1.22733449e-03, 5.24487464e-03,\n",
       "        1.78434531e-02, 2.66415468e-03, 5.84871255e-04, 2.04054216e-02,\n",
       "        2.43199453e-03, 3.94232703e-03, 2.87632311e-02, 1.03868477e-02,\n",
       "        6.82058871e-04, 1.77060224e-02, 3.36830614e-03, 1.12990400e-02,\n",
       "        2.20948893e-02, 1.82682459e-03, 4.01036623e-03, 5.01302060e-02,\n",
       "        5.24161415e-03, 2.40554093e-03, 3.11180753e-03, 1.70302317e-03,\n",
       "        2.74946113e-03, 8.16156569e-04, 9.20726669e-04, 2.32922634e-03,\n",
       "        7.71041999e-04, 1.16029653e-03, 5.50072822e-03, 1.06620304e-02,\n",
       "        1.06191825e-03, 1.28610416e-03, 2.50982289e-03, 3.75047866e-03,\n",
       "        1.04753128e-03, 2.33778822e-03, 6.62510924e-03, 1.42372701e-03,\n",
       "        2.53329420e-03, 2.36321446e-03, 1.07018046e-02, 3.36514646e-03,\n",
       "        4.24835250e-03, 5.20643028e-03, 4.26317013e-04, 7.51779105e-03,\n",
       "        1.22678453e-02, 3.50262725e-03, 4.97744110e-04, 1.20483698e-03,\n",
       "        2.32532167e-03, 2.49256374e-03, 1.07459550e-03, 7.50906543e-03,\n",
       "        1.68476207e-03, 5.17220507e-03, 5.45044508e-03, 4.57021778e-03,\n",
       "        7.19811822e-03, 1.33328378e-02, 3.58733267e-03, 7.84997528e-03,\n",
       "        3.50071846e-03, 3.83281499e-03, 8.16739706e-04, 4.76097689e-03,\n",
       "        2.49482583e-03, 8.63881278e-03, 1.69211333e-02, 7.32641731e-03,\n",
       "        4.85126061e-03, 1.33256340e-02, 5.61266385e-03, 1.46066289e-02,\n",
       "        2.00293140e-03, 5.95637040e-03, 2.07047565e-02, 1.72459416e-02]),\n",
       " 'mean_score_time': array([0.00098936, 0.00032274, 0.        , 0.00099746, 0.        ,\n",
       "        0.00033228, 0.00033251, 0.00066336, 0.00034149, 0.00053922,\n",
       "        0.00099818, 0.00066702, 0.00067377, 0.00032949, 0.00066415,\n",
       "        0.00100573, 0.00068069, 0.00066527, 0.00099667, 0.00098507,\n",
       "        0.0003322 , 0.00066471, 0.00099428, 0.0003318 , 0.00066471,\n",
       "        0.00033236, 0.00098896, 0.00065565, 0.00033243, 0.00096917,\n",
       "        0.00100652, 0.00066487, 0.00065414, 0.00100684, 0.00066503,\n",
       "        0.00066487, 0.00099675, 0.00099436, 0.00099762, 0.00133006,\n",
       "        0.00099754, 0.00099746, 0.00133038, 0.00133014, 0.00100652,\n",
       "        0.00098403, 0.00064937, 0.00066495, 0.00099579, 0.0009985 ,\n",
       "        0.00066392, 0.00100501, 0.00131838, 0.00099826, 0.00099452,\n",
       "        0.00133816, 0.00165192, 0.00165995, 0.00098634, 0.00133038,\n",
       "        0.00033204, 0.00034332, 0.00033307, 0.00033251, 0.00033236,\n",
       "        0.0003291 , 0.00033212, 0.00033331, 0.00067433, 0.00033228,\n",
       "        0.00066471, 0.00033236, 0.00033251, 0.00066876, 0.00098809,\n",
       "        0.00068092, 0.00067671, 0.00066471, 0.00099715, 0.00066344,\n",
       "        0.00067433, 0.00102035, 0.00100668, 0.00066368, 0.00066272,\n",
       "        0.00066495, 0.00066519, 0.0009973 , 0.00098634, 0.00100589,\n",
       "        0.00033323, 0.00067361, 0.00033236, 0.00065573, 0.00099317,\n",
       "        0.00066598, 0.00100096, 0.00066153, 0.0009985 , 0.00099524,\n",
       "        0.00099826, 0.0009977 , 0.00100168, 0.00133093, 0.00132934,\n",
       "        0.00098705, 0.00033283, 0.00033935, 0.00067449, 0.00100867,\n",
       "        0.00099476, 0.00099691, 0.00099746, 0.00100867, 0.00099738,\n",
       "        0.0013322 , 0.00099778, 0.00166138, 0.00166488, 0.00165915,\n",
       "        0.00054328, 0.00065406, 0.00067965, 0.00066717, 0.00065351,\n",
       "        0.        , 0.00066479, 0.00033251, 0.00033236, 0.00066471,\n",
       "        0.00099746, 0.00099468, 0.00066161, 0.00033259, 0.00066447,\n",
       "        0.00033402, 0.00032059, 0.        , 0.00063904, 0.00033259,\n",
       "        0.00033251, 0.00066495, 0.00100032, 0.00098642, 0.00066487,\n",
       "        0.0009954 , 0.00099643, 0.00098904, 0.00098777, 0.00099667,\n",
       "        0.00034332, 0.0009985 , 0.00033267, 0.00099691, 0.0009857 ,\n",
       "        0.00066495, 0.0009973 , 0.00099818, 0.00099874, 0.00099532,\n",
       "        0.0016733 , 0.00099436, 0.00099778, 0.00133014, 0.00099961,\n",
       "        0.00065502, 0.00099222, 0.00084162, 0.00066789, 0.00100644,\n",
       "        0.00100032, 0.00100414, 0.00099421, 0.0009985 , 0.0013291 ,\n",
       "        0.00132974, 0.00133204, 0.00166241, 0.00136606, 0.00099715]),\n",
       " 'std_score_time': array([1.12408454e-05, 4.56422271e-04, 0.00000000e+00, 7.37000982e-07,\n",
       "        0.00000000e+00, 4.69909263e-04, 4.70246438e-04, 4.69068033e-04,\n",
       "        4.82946688e-04, 4.11170902e-04, 1.23630756e-06, 4.72356099e-04,\n",
       "        4.76557173e-04, 4.65975557e-04, 4.69630553e-04, 1.19198693e-05,\n",
       "        4.81706591e-04, 4.70415035e-04, 4.49566384e-07, 8.07599955e-04,\n",
       "        4.69796871e-04, 4.70022017e-04, 4.11267250e-06, 4.69234913e-04,\n",
       "        4.70021816e-04, 4.70021655e-04, 1.14639428e-05, 4.63752799e-04,\n",
       "        4.70134046e-04, 4.01242720e-05, 1.28692058e-05, 4.70134207e-04,\n",
       "        4.62734218e-04, 1.28141207e-05, 4.70246478e-04, 4.70134409e-04,\n",
       "        1.07214749e-06, 4.33691777e-06, 4.49566384e-07, 4.69740928e-04,\n",
       "        8.92080638e-07, 5.61957980e-07, 4.69516387e-04, 4.70359474e-04,\n",
       "        2.54124333e-05, 1.44583827e-05, 4.59257573e-04, 4.70190252e-04,\n",
       "        2.11484432e-05, 1.68587394e-06, 4.69461150e-04, 1.40233008e-05,\n",
       "        4.77516062e-04, 1.34869915e-06, 2.86983968e-06, 4.63771647e-04,\n",
       "        4.85983172e-04, 4.67899335e-04, 1.55112619e-05, 4.70527910e-04,\n",
       "        4.69572088e-04, 4.85531695e-04, 4.71033179e-04, 4.70246438e-04,\n",
       "        4.70021655e-04, 4.65413599e-04, 4.69684480e-04, 4.71370354e-04,\n",
       "        4.76952711e-04, 4.69909263e-04, 4.70022017e-04, 4.70021655e-04,\n",
       "        4.70246438e-04, 4.73880542e-04, 1.32063712e-05, 4.81878965e-04,\n",
       "        4.78682299e-04, 4.70021655e-04, 2.24783192e-07, 4.69125793e-04,\n",
       "        4.76966774e-04, 3.27622948e-05, 1.29382206e-05, 4.69292331e-04,\n",
       "        4.68624129e-04, 4.70190252e-04, 4.70358991e-04, 1.94667955e-07,\n",
       "        1.63555840e-05, 1.28259446e-05, 4.71257962e-04, 4.76468474e-04,\n",
       "        4.70021655e-04, 4.63797386e-04, 2.11071896e-05, 4.70920787e-04,\n",
       "        5.52093329e-06, 4.67795250e-04, 3.27482188e-06, 3.26516447e-06,\n",
       "        7.78671819e-07, 4.89903609e-07, 7.36229298e-06, 4.70302885e-04,\n",
       "        4.70077941e-04, 1.62031109e-05, 4.70696004e-04, 4.79912115e-04,\n",
       "        4.77079131e-04, 1.50415903e-05, 2.43399824e-06, 2.97360213e-07,\n",
       "        1.12391596e-07, 1.52542353e-05, 6.83651389e-07, 4.69750366e-04,\n",
       "        2.05095417e-06, 4.68227436e-04, 4.68673117e-04, 4.68338370e-04,\n",
       "        4.11939532e-04, 4.62680819e-04, 4.80659359e-04, 4.71772169e-04,\n",
       "        4.62268602e-04, 0.00000000e+00, 4.70077941e-04, 4.70246438e-04,\n",
       "        4.70021655e-04, 4.70021816e-04, 8.14198815e-04, 2.75989459e-06,\n",
       "        4.67832945e-04, 4.70358829e-04, 4.69853077e-04, 4.72381878e-04,\n",
       "        4.53387698e-04, 0.00000000e+00, 4.52781775e-04, 4.70358829e-04,\n",
       "        4.70246438e-04, 4.70190333e-04, 8.17704368e-04, 1.15172599e-05,\n",
       "        4.70134046e-04, 1.78416128e-06, 8.10467325e-07, 1.05306787e-05,\n",
       "        1.28362815e-05, 2.31158121e-05, 4.85531695e-04, 1.36267568e-06,\n",
       "        4.70471221e-04, 7.86741172e-07, 1.52318604e-05, 4.70190252e-04,\n",
       "        0.00000000e+00, 2.13544032e-06, 1.08386530e-06, 4.56260048e-06,\n",
       "        4.78130230e-04, 4.16304298e-06, 3.37174788e-07, 4.72382239e-04,\n",
       "        2.46494014e-06, 4.63497014e-04, 7.53275274e-06, 6.25601023e-04,\n",
       "        4.72278514e-04, 1.29264994e-05, 3.46816864e-05, 7.01165040e-06,\n",
       "        4.89774670e-06, 3.37174788e-07, 4.68959682e-04, 4.70134086e-04,\n",
       "        4.44711603e-04, 4.70134086e-04, 4.46989092e-04, 6.83651389e-07]),\n",
       " 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 100, 100, 200, 200, 200, 300, 300, 300, 400, 400,\n",
       "                    400, 500, 500, 500, 100, 100, 100, 200, 200, 200, 300,\n",
       "                    300, 300, 400, 400, 400, 500, 500, 500, 100, 100, 100,\n",
       "                    200, 200, 200, 300, 300, 300, 400, 400, 400, 500, 500,\n",
       "                    500, 100, 100, 100, 200, 200, 200, 300, 300, 300, 400,\n",
       "                    400, 400, 500, 500, 500, 100, 100, 100, 200, 200, 200,\n",
       "                    300, 300, 300, 400, 400, 400, 500, 500, 500, 100, 100,\n",
       "                    100, 200, 200, 200, 300, 300, 300, 400, 400, 400, 500,\n",
       "                    500, 500, 100, 100, 100, 200, 200, 200, 300, 300, 300,\n",
       "                    400, 400, 400, 500, 500, 500, 100, 100, 100, 200, 200,\n",
       "                    200, 300, 300, 300, 400, 400, 400, 500, 500, 500, 100,\n",
       "                    100, 100, 200, 200, 200, 300, 300, 300, 400, 400, 400,\n",
       "                    500, 500, 500, 100, 100, 100, 200, 200, 200, 300, 300,\n",
       "                    300, 400, 400, 400, 500, 500, 500, 100, 100, 100, 200,\n",
       "                    200, 200, 300, 300, 300, 400, 400, 400, 500, 500, 500,\n",
       "                    100, 100, 100, 200, 200, 200, 300, 300, 300, 400, 400,\n",
       "                    400, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1,\n",
       "                    0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1, 0.5, 0.7, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.001,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 100, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 200, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 300, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 400, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 200, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 300, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 400, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 500, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 400, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 400, 'subsample': 1},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 200, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 300, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 400, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 1,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 300, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 400, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 500, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 400, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 400,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 400, 'subsample': 1},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'n_estimators': 500,\n",
       "   'subsample': 0.7},\n",
       "  {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500, 'subsample': 1}],\n",
       " 'split0_test_score': array([0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.85915493, 0.85915493, 0.86619718, 0.86619718,\n",
       "        0.86619718, 0.86619718, 0.86619718, 0.86619718, 0.86619718,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.87323944, 0.87323944, 0.85915493, 0.9084507 ,\n",
       "        0.9084507 , 0.86619718, 0.91549296, 0.92253521, 0.9084507 ,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.88732394, 0.88028169, 0.91549296, 0.90140845,\n",
       "        0.9084507 , 0.91549296, 0.91549296, 0.91549296, 0.92253521,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.8943662 , 0.88732394, 0.91549296, 0.9084507 ,\n",
       "        0.9084507 , 0.91549296, 0.92253521, 0.92253521, 0.92253521,\n",
       "        0.87323944, 0.87323944, 0.86619718, 0.91549296, 0.91549296,\n",
       "        0.92253521, 0.92253521, 0.92957746, 0.92957746, 0.94366197,\n",
       "        0.95070423, 0.93661972, 0.95070423, 0.95070423, 0.94366197,\n",
       "        0.93661972, 0.92253521, 0.91549296, 0.95070423, 0.95774648,\n",
       "        0.95070423, 0.94366197, 0.96478873, 0.95070423, 0.95070423,\n",
       "        0.95070423, 0.95070423, 0.95070423, 0.95070423, 0.95070423,\n",
       "        0.93661972, 0.93661972, 0.92253521, 0.95070423, 0.95774648,\n",
       "        0.95070423, 0.95070423, 0.96478873, 0.95070423, 0.94366197,\n",
       "        0.95774648, 0.95070423, 0.95070423, 0.95774648, 0.95774648,\n",
       "        0.95070423, 0.95070423, 0.91549296, 0.95070423, 0.95774648,\n",
       "        0.92957746, 0.95070423, 0.96478873, 0.95070423, 0.95774648,\n",
       "        0.96478873, 0.95070423, 0.95774648, 0.96478873, 0.95070423,\n",
       "        0.95774648, 0.94366197, 0.95070423, 0.96478873, 0.95070423,\n",
       "        0.94366197, 0.96478873, 0.95774648, 0.94366197, 0.96478873,\n",
       "        0.95070423, 0.94366197, 0.96478873, 0.95774648, 0.94366197,\n",
       "        0.94366197, 0.94366197, 0.95774648, 0.95070423, 0.95070423,\n",
       "        0.95774648, 0.96478873, 0.95070423, 0.95774648, 0.96478873,\n",
       "        0.95070423, 0.96478873, 0.96478873, 0.95070423, 0.96478873,\n",
       "        0.94366197, 0.95774648, 0.95774648, 0.95774648, 0.96478873,\n",
       "        0.95774648, 0.95070423, 0.95070423, 0.96478873, 0.95070423,\n",
       "        0.95070423, 0.97183099, 0.95070423, 0.95070423, 0.97183099,\n",
       "        0.94366197, 0.97183099, 0.95070423, 0.94366197, 0.96478873,\n",
       "        0.95774648, 0.95070423, 0.95774648, 0.95774648, 0.94366197,\n",
       "        0.95774648, 0.95774648, 0.95774648, 0.95070423, 0.95774648]),\n",
       " 'split1_test_score': array([0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.90140845, 0.90140845, 0.90140845, 0.90140845,\n",
       "        0.90140845, 0.90140845, 0.90140845, 0.90140845, 0.90140845,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.90140845, 0.8943662 , 0.88028169, 0.92957746,\n",
       "        0.91549296, 0.88732394, 0.94366197, 0.95070423, 0.8943662 ,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.8943662 , 0.90140845, 0.90140845, 0.92253521,\n",
       "        0.92957746, 0.90140845, 0.95070423, 0.94366197, 0.9084507 ,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.8943662 , 0.90140845, 0.8943662 , 0.92957746,\n",
       "        0.92957746, 0.90140845, 0.95774648, 0.93661972, 0.90140845,\n",
       "        0.92253521, 0.92253521, 0.9084507 , 0.92253521, 0.9084507 ,\n",
       "        0.9084507 , 0.92957746, 0.92253521, 0.92253521, 0.93661972,\n",
       "        0.93661972, 0.92957746, 0.95070423, 0.94366197, 0.95774648,\n",
       "        0.94366197, 0.95070423, 0.94366197, 0.94366197, 0.95774648,\n",
       "        0.94366197, 0.94366197, 0.94366197, 0.94366197, 0.95070423,\n",
       "        0.95070423, 0.94366197, 0.95070423, 0.95774648, 0.94366197,\n",
       "        0.95070423, 0.95070423, 0.92957746, 0.95070423, 0.94366197,\n",
       "        0.94366197, 0.95070423, 0.94366197, 0.94366197, 0.95774648,\n",
       "        0.95774648, 0.94366197, 0.95774648, 0.96478873, 0.95070423,\n",
       "        0.95070423, 0.95774648, 0.9084507 , 0.95070423, 0.95070423,\n",
       "        0.91549296, 0.95774648, 0.95070423, 0.91549296, 0.95774648,\n",
       "        0.96478873, 0.93661972, 0.95774648, 0.95774648, 0.92957746,\n",
       "        0.94366197, 0.95070423, 0.95774648, 0.96478873, 0.95774648,\n",
       "        0.96478873, 0.96478873, 0.96478873, 0.97183099, 0.96478873,\n",
       "        0.96478873, 0.97183099, 0.96478873, 0.96478873, 0.97183099,\n",
       "        0.97887324, 0.95774648, 0.95070423, 0.97183099, 0.95774648,\n",
       "        0.96478873, 0.97183099, 0.96478873, 0.97183099, 0.97183099,\n",
       "        0.95774648, 0.97183099, 0.97183099, 0.95774648, 0.97183099,\n",
       "        0.97183099, 0.96478873, 0.95070423, 0.97183099, 0.97183099,\n",
       "        0.95774648, 0.97887324, 0.97183099, 0.95774648, 0.97887324,\n",
       "        0.97183099, 0.95774648, 0.97887324, 0.97183099, 0.95774648,\n",
       "        0.96478873, 0.95774648, 0.94366197, 0.95774648, 0.97183099,\n",
       "        0.94366197, 0.96478873, 0.97183099, 0.94366197, 0.96478873,\n",
       "        0.96478873, 0.94366197, 0.95774648, 0.96478873, 0.94366197]),\n",
       " 'split2_test_score': array([0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.91549296, 0.92253521, 0.92957746, 0.92957746,\n",
       "        0.92957746, 0.92957746, 0.92957746, 0.93661972, 0.92957746,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.92253521, 0.95070423, 0.91549296, 0.95774648,\n",
       "        0.95070423, 0.95774648, 0.96478873, 0.96478873, 0.96478873,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.92957746, 0.96478873, 0.94366197, 0.95774648,\n",
       "        0.96478873, 0.95774648, 0.97887324, 0.97183099, 0.95774648,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.94366197, 0.95774648, 0.95774648, 0.95774648,\n",
       "        0.97183099, 0.95774648, 0.97887324, 0.97183099, 0.95070423,\n",
       "        0.95070423, 0.95070423, 0.97183099, 0.95070423, 0.95070423,\n",
       "        0.95070423, 0.95774648, 0.95774648, 0.97183099, 0.95070423,\n",
       "        0.99295775, 0.98591549, 0.97183099, 0.98591549, 0.99295775,\n",
       "        0.97183099, 0.97183099, 0.97183099, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97887324, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.98591549, 0.98591549, 0.97887324,\n",
       "        0.97887324, 0.97183099, 0.96478873, 0.97887324, 0.97183099,\n",
       "        0.96478873, 0.97887324, 0.97887324, 0.96478873, 0.97887324,\n",
       "        0.97887324, 0.96478873, 0.99295775, 0.97887324, 0.96478873,\n",
       "        0.97887324, 0.97183099, 0.95070423, 0.97183099, 0.97183099,\n",
       "        0.95774648, 0.97887324, 0.98591549, 0.95774648, 0.97887324,\n",
       "        0.98591549, 0.95774648, 0.98591549, 0.98591549, 0.95774648,\n",
       "        0.98591549, 0.98591549, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.97887324, 0.97887324, 0.97183099, 0.97887324, 0.97183099,\n",
       "        0.97183099, 0.97887324, 0.97183099, 0.97183099, 0.97887324,\n",
       "        0.97183099, 0.98591549, 0.99295775, 0.97887324, 0.98591549,\n",
       "        0.99295775, 0.97887324, 0.97887324, 0.99295775, 0.97887324,\n",
       "        0.97887324, 0.98591549, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.98591549, 0.97887324, 0.98591549,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97183099, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.98591549, 0.98591549, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97183099, 0.98591549,\n",
       "        0.97183099, 0.97183099, 0.98591549, 0.95070423, 0.97887324,\n",
       "        0.98591549, 0.92253521, 0.97887324, 0.98591549, 0.93661972]),\n",
       " 'mean_test_score': array([0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.89201878, 0.8943662 , 0.89906103, 0.89906103,\n",
       "        0.89906103, 0.89906103, 0.89906103, 0.90140845, 0.89906103,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.89906103, 0.90610329, 0.88497653, 0.93192488,\n",
       "        0.92488263, 0.90375587, 0.94131455, 0.94600939, 0.92253521,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.90375587, 0.91549296, 0.92018779, 0.92723005,\n",
       "        0.9342723 , 0.92488263, 0.94835681, 0.94366197, 0.92957746,\n",
       "        0.62676056, 0.62676056, 0.62676056, 0.62676056, 0.62676056,\n",
       "        0.62676056, 0.91079812, 0.91549296, 0.92253521, 0.93192488,\n",
       "        0.93661972, 0.92488263, 0.95305164, 0.94366197, 0.92488263,\n",
       "        0.91549296, 0.91549296, 0.91549296, 0.92957746, 0.92488263,\n",
       "        0.92723005, 0.93661972, 0.93661972, 0.94131455, 0.94366197,\n",
       "        0.9600939 , 0.95070423, 0.95774648, 0.9600939 , 0.96478873,\n",
       "        0.95070423, 0.94835681, 0.94366197, 0.95774648, 0.96478873,\n",
       "        0.95539906, 0.95539906, 0.96244131, 0.95774648, 0.96244131,\n",
       "        0.96244131, 0.95774648, 0.96244131, 0.96478873, 0.95774648,\n",
       "        0.95539906, 0.95305164, 0.93896714, 0.9600939 , 0.95774648,\n",
       "        0.95305164, 0.9600939 , 0.96244131, 0.95305164, 0.9600939 ,\n",
       "        0.96478873, 0.95305164, 0.96713615, 0.96713615, 0.95774648,\n",
       "        0.9600939 , 0.9600939 , 0.92488263, 0.95774648, 0.9600939 ,\n",
       "        0.9342723 , 0.96244131, 0.96713615, 0.94131455, 0.96478873,\n",
       "        0.97183099, 0.94835681, 0.96713615, 0.96948357, 0.94600939,\n",
       "        0.96244131, 0.9600939 , 0.96244131, 0.96713615, 0.9600939 ,\n",
       "        0.96244131, 0.96948357, 0.96478873, 0.96478873, 0.96713615,\n",
       "        0.96244131, 0.96478873, 0.96713615, 0.96478873, 0.96478873,\n",
       "        0.96478873, 0.96244131, 0.96713615, 0.96713615, 0.96478873,\n",
       "        0.97183099, 0.97183099, 0.96478873, 0.9741784 , 0.97183099,\n",
       "        0.96244131, 0.9741784 , 0.97183099, 0.96244131, 0.97183099,\n",
       "        0.96478873, 0.96713615, 0.96478873, 0.96948357, 0.9741784 ,\n",
       "        0.96478873, 0.96948357, 0.96713615, 0.96478873, 0.97183099,\n",
       "        0.96948357, 0.96948357, 0.97183099, 0.96948357, 0.96948357,\n",
       "        0.96244131, 0.96948357, 0.95774648, 0.95774648, 0.9741784 ,\n",
       "        0.95774648, 0.96244131, 0.97183099, 0.95070423, 0.96244131,\n",
       "        0.96948357, 0.94131455, 0.96478873, 0.96713615, 0.94600939]),\n",
       " 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02393906, 0.0263497 , 0.02592808, 0.02592808,\n",
       "        0.02592808, 0.02592808, 0.02592808, 0.02874988, 0.02592808,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02019325, 0.03269575, 0.02323825, 0.02019325,\n",
       "        0.01848359, 0.03913928, 0.02019325, 0.01756647, 0.03042601,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01848359, 0.03590859, 0.01756647, 0.02323825,\n",
       "        0.02323825, 0.02393906, 0.02592808, 0.0229999 , 0.02073183,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02323825, 0.03042601, 0.0263497 , 0.02019325,\n",
       "        0.0263497 , 0.02393906, 0.02323825, 0.02073183, 0.02019325,\n",
       "        0.03201451, 0.03201451, 0.04341137, 0.01521301, 0.01848359,\n",
       "        0.01756647, 0.01521301, 0.01521301, 0.02176906, 0.00574998,\n",
       "        0.02393906, 0.02506356, 0.00995925, 0.01848359, 0.02073183,\n",
       "        0.01521301, 0.02019325, 0.0229999 , 0.01521301, 0.00995925,\n",
       "        0.01196953, 0.01659875, 0.01447046, 0.01521301, 0.01659875,\n",
       "        0.01659875, 0.01521301, 0.01659875, 0.01521301, 0.01521301,\n",
       "        0.01756647, 0.01447046, 0.01848359, 0.013279  , 0.01149995,\n",
       "        0.00878323, 0.013279  , 0.01447046, 0.00878323, 0.01447046,\n",
       "        0.00995925, 0.00878323, 0.01848359, 0.00878323, 0.00574998,\n",
       "        0.013279  , 0.00878323, 0.01848359, 0.00995925, 0.00878323,\n",
       "        0.01756647, 0.01196953, 0.01447046, 0.01848359, 0.00995925,\n",
       "        0.00995925, 0.00878323, 0.013279  , 0.01196953, 0.01196953,\n",
       "        0.01756647, 0.01848359, 0.01196953, 0.00331975, 0.00878323,\n",
       "        0.01447046, 0.0066395 , 0.00574998, 0.01521301, 0.00331975,\n",
       "        0.00878323, 0.01521301, 0.00331975, 0.00574998, 0.01521301,\n",
       "        0.01521301, 0.01756647, 0.01848359, 0.01196953, 0.01521301,\n",
       "        0.01521301, 0.00574998, 0.01149995, 0.01447046, 0.00574998,\n",
       "        0.01196953, 0.00878323, 0.00574998, 0.01196953, 0.00574998,\n",
       "        0.01521301, 0.00878323, 0.01521301, 0.00878323, 0.00878323,\n",
       "        0.00995925, 0.013279  , 0.01196953, 0.00574998, 0.01521301,\n",
       "        0.01447046, 0.00878323, 0.01521301, 0.01447046, 0.00878323,\n",
       "        0.01447046, 0.00878323, 0.01521301, 0.01149995, 0.00878323,\n",
       "        0.01149995, 0.00878323, 0.01149995, 0.00574998, 0.01447046,\n",
       "        0.01196953, 0.01447046, 0.00995925, 0.01447046, 0.00878323]),\n",
       " 'rank_test_score': array([157, 157, 157, 157, 157, 157, 155, 154, 147, 147, 147, 147, 147,\n",
       "        146, 147, 157, 157, 157, 157, 157, 157, 153, 143, 156, 122, 128,\n",
       "        144, 112, 105, 134, 157, 157, 157, 157, 157, 157, 144, 137, 136,\n",
       "        126, 120, 128, 102, 108, 124, 157, 157, 157, 157, 157, 157, 142,\n",
       "        138, 134, 122, 117, 128,  94, 108, 128, 138, 138, 138, 124, 128,\n",
       "        126, 117, 117, 112, 111,  70,  99,  80,  70,  41,  99, 102, 108,\n",
       "         80,  41,  91,  91,  54,  80,  54,  54,  80,  54,  41,  80,  91,\n",
       "         94, 116,  70,  80,  94,  70,  54,  94,  70,  41,  94,  29,  29,\n",
       "         80,  70,  70, 128,  80,  70, 121,  54,  24, 112,  41,   5, 102,\n",
       "         29,  14, 105,  54,  70,  54,  24,  70,  54,  14,  41,  36,  24,\n",
       "         54,  36,  24,  41,  36,  41,  54,  29,  29,  41,   5,   5,  36,\n",
       "          1,   5,  54,   1,   5,  54,   5,  36,  29,  41,  14,   1,  41,\n",
       "         14,  29,  41,   5,  14,  14,   5,  14,  14,  54,  14,  80,  80,\n",
       "          1,  80,  54,   5,  99,  54,  14, 112,  41,  24, 105])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 300, 'subsample': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 8.65803996e-03, 1.02445423e-03, 4.71192918e-03,\n",
       "       7.56521751e-04, 6.69281750e-04, 1.43741151e-02, 1.12214244e-01,\n",
       "       4.58008512e-05, 1.02227966e-03, 3.72550544e-03, 2.33289667e-03,\n",
       "       5.07636464e-08, 1.59976825e-02, 2.45791089e-04, 9.09423897e-04,\n",
       "       7.82762406e-05, 3.69521728e-05, 4.27091800e-04, 5.18519744e-03,\n",
       "       2.79913093e-01, 2.96846699e-02, 9.73630056e-02, 6.13601810e-02,\n",
       "       4.73295020e-04, 1.56392178e-03, 2.02925214e-02, 3.35375358e-01,\n",
       "       1.54926340e-03, 9.15643250e-06])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gs.best_estimator_\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost(Extra Gradient Boost)\n",
    "- https://xgboost.readthedocs.io/\n",
    "- Gradient Boost 알고리즘을 기반으로 개선해서 나온 모델.\n",
    "- 캐글 경진대회에서 상위에 입상한 데이터 과학자들이 사용한 것으로 알려저 유명해짐.\n",
    "- Gradient Boost의 단점인 느린수행시간을 해결하고 과적합을 제어할 수 있는 규제를 제공하여 성능을 높임.\n",
    "- 두가지 개발 방법\n",
    "    - [Scikit-learn 래퍼 XGBoost 모듈 사용](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)\n",
    "    - [파이썬 래퍼 XGBoost 모듈 사용](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.training)\n",
    "- 설치   \n",
    "``\n",
    "pip install xgboost\n",
    "conda install -y -c anaconda py-xgboost\n",
    "``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.3.3-py3-none-win_amd64.whl (95.2 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\inje.jeong\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\inje.jeong\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn 래퍼 XGBoost\n",
    "- XGBoost를 Scikit-learn프레임워크와 연동할 수 있도록 개발됨.\n",
    "- Scikit-learn의 Estimator들과 동일한 패턴으로 코드를 작성할 수 있다.\n",
    "- GridSearchCV나 Pipeline 등 Scikit-learn이 제공하는 다양한 유틸리티들을 사용할 수 있다.\n",
    "- XGBClassifier: 분류\n",
    "- XGBRegressor : 회귀 \n",
    "\n",
    "### 주요 매개변수\n",
    "- learning_rate : 학습률, 보통 0.01 ~ 0.2 사이의 값 사용\n",
    "- n_estimators : week tree 개수\n",
    "- max_depth: 트리의 depth 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=200,\n",
    "                   learning_rate=0.5,\n",
    "                   max_depth=2,\n",
    "                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:32:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.5, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=12, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = xgb.predict(X_train)\n",
    "pred_test = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.965034965034965)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, pred_train), accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 1.7377844e-02, 0.0000000e+00, 2.7057502e-02,\n",
       "       9.4335829e-04, 5.7103140e-03, 3.3941608e-02, 9.9188931e-02,\n",
       "       4.1985163e-03, 2.1932845e-03, 0.0000000e+00, 3.3285678e-04,\n",
       "       1.7986957e-02, 1.1520459e-02, 0.0000000e+00, 2.2246058e-03,\n",
       "       0.0000000e+00, 1.2838596e-03, 9.7346597e-04, 8.4046111e-04,\n",
       "       2.2470552e-01, 1.2404799e-02, 1.2866795e-01, 4.5809176e-02,\n",
       "       4.1861958e-03, 1.6558268e-04, 1.2857459e-02, 3.3936533e-01,\n",
       "       4.8814113e-03, 1.1825919e-03], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = xgb.feature_importances_\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
