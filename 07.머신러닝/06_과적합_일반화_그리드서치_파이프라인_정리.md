# 05. 과적합
- 과(대)적합 - 중요! 모델이 데이터에 비해 복잡할 때 훈련 데이터셋에만 포커스되어 새로운 예측 데이터를 제대로(일반적)으로 예측하지 못하는 상황
  - 원인
    - 데이터에 비해 복잡한 모델 -> 피쳐개수 줄이기, 규제 하이퍼파라미터 설정
    - 데이터상의 문제 -> 데이터 전처리, 더 많은 데이터 수집(현실적으로 어려움)
- 과소적합 - 모델이 주어진 데이터의 패턴조차 파악 불가한 상황
```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

cancer = load_breast_cancer()
X = cancer['data']
y = cancer['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)

# 정확도 - max_depth 주지 않았을 때
tree = DecisionTreeClassifier(random_state=1)
tree.fit(X_train, y_train)
pred_train = tree.predict(X_train)
pred_test = tree.predict(X_test)
print("Train정확도:", accuracy_score(y_train, pred_train))
print("Test정확도:", accuracy_score(y_test, pred_test))

# 정확도 - max_depth=2
tree = DecisionTreeClassifier(max_depth=4, random_state=1)
tree.fit(X_train, y_train)
pred_train = tree.predict(X_train)
pred_test = tree.predict(X_test)
print("Train정확도:", accuracy_score(y_train, pred_train))
print("Test정확도:", accuracy_score(y_test, pred_test))
```

### graphviz
- 훈련모델 가시화 작업(Tree 모델)
```python
from sklearn.tree import export_graphviz
from graphviz import Source

graph = Source(export_graphviz(tree, # 학습한 모델
                              out_file=None, # 이미지로 저장할 때 파일경로
                              feature_names=cancer['feature_names'], # Feature(컬럼)의 이름
                              class_names=cancer['target_names'], # Label의 class 이름
                              rounded=True,
                              filled=True))
graph
```
- - -
### GridSearch
- 하이퍼파라미터를 변경하면서 원하는 성능지표 기준으로 최적의 모델 찾아주는 라이브러리
- `GridSearchCV()`: 지정한 하이퍼파라미터에 대해 모든 조합을 교차검증 / `RaondomizedSearchCV()`: 모든 조합이 아닌 임의의 값만 대입해 지정한 횟수만큼 평가
- 1. `GridSearchCV`
  - 주요 매개변수
      - estimator: 모델객체 지정
      - params : 하이퍼파라미터 목록을 dictionary로 전달 '파라미터명':[파라미터값 list] 형식
      - scoring: 평가 지표
      - cv : 교차검증시 fold 개수. (K-fold)
      - n_jobs : 사용할 CPU 코어 개수 (None:1(기본값), -1: 모든 코어 다 사용)
  - 메소드
      - fit(X, y) : 학습
      - predict(X): 제일 좋은 성능을 낸 모델로 predict()
      - predict_proba(X): 제일 좋은 성능을 낸 모델로 predict_proba() 호출
  - 결과 조회 변수
      - cv_results_ : 파라미터 조합별 결과 조회
      - best_params_ : 가장 좋은 성능을 낸 parameter 조합 조회
      - best_estimator_ : 가장 좋은 성능을 낸 모델 반환       
  ```python
  from sklearn.datasets import load_breast_cancer
  from sklearn.model_selection import train_test_split
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.model_selection import GridSearchCV

  X, y = load_breast_cancer(return_X_y=True)
  X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)

  tree = DecisionTreeClassifier()
  # 하이퍼파라미터 후보들을 딕셔너리로 지정. 파라미터이름:[후보]
  param_grid = {
      "max_depth": range(1,11),
      "max_leaf_nodes": [3,5,7,9],
      "random_state":[1]
  }
  grid_search = GridSearchCV(tree, # 학습시킬 모델
                            param_grid=param_grid, # 하이퍼파라미터 후보
  #                           scoring="accuracy", # 평가지표
                              scoring=['accuracy', 'recall', 'precision'], # 평가지표를 여러개 지정시 리스트로 묶어줌
                             refit="accuracy", # 평가지표가 여러개일 때 최우선 기준으로 삼을 지표 지정
                            cv=5, # 교차검증(Cross Validation)의 folder 개수(몇 개로 나눌 건지)
                             n_jobs=-1
                            )
  # 학습 - 최적의 하이퍼파라미터 조합
  grid_search.fit(X_train, y_train)
  from sklearn.metrics import accuracy_score
  pred_train = grid_search.predict(X_train) # 가장 성능이 잘나온 하이퍼파라미터를 가진 모델(tree)로 에측
  accuracy_score(y_train, pred_train)
  import pandas as pd
  
  # 하이퍼파라미터 조합별 결과
  df = pd.DataFrame(grid_search.cv_results_)#.sort_values('rank_test_score')
  # 최적의 하이퍼파라미터
  best_param = grid_search.best_params_
  # 최적의 모델
  best_estimator = grid_search.best_estimator_
  ```
- 2. `RaondomizedSearchCV`
  - 주요 매개변수
      - estimator: 모델객체 지정
      - param_distributions : 하이퍼파라미터 목록을 dictionary로 전달 '파라미터명':[파라미터값 list] 형식
      - n_iter : 파라미터 검색 횟수
      - scoring: 평가 지표
      - cv : 교차검증시 fold 개수. 
      - n_jobs : 사용할 CPU 코어 개수 (None:1(기본값), -1: 모든 코어 다 사용)
```python
from sklearn.model_selection import RandomizedSearchCV

tree = DecisionTreeClassifier()
param_grid = {
    "max_depth":range(1,21),
    "max_leaf_nodes":range(2,11),
    "criterion":["gini","entropy"],
    "random_state":[1]
}
n_iter = 50 # 확인할 조합의 개수. default:10
randomized_search = RandomizedSearchCV(tree,
                                      param_distributions=param_grid,
                                      n_iter=n_iter,
                                      scoring="accuracy",
                                      cv=3,
                                      n_jobs=2)
randomized_search.fit(X_train, y_train)
df = pd.DataFrame(randomized_search.cv_results_)
```
- - -
### 파이프라인(Pipeline)
- 다양한 머신러닝 프로세스를 한번에 처리되도록 만들어 놓은 모델
- 전처리 작업 파이프라인과 전체 프로세스 파이프라인으로 나뉜다. 차이는 마지막 모델이 변환기/추정기 여부에 따라 순서대로 전처리/전프 로 구분
- 생성
  - (이름, 변환기) 를 리스트로 묶어서 전달한다.
    - `pipeline.fit()`
      - 각 순서대로 각 변환기의 fit_transform()이 실행되고 결과가 다음 단계로 전달된다. 마지막 단계에서는 fit()만 호출한다.
      - 보통 마지막이 추정기일때 사용
    - `pipeline.fit_transform()`
      - fit()과 동일하나 마지막 단계에서도 fit_transform()이 실행된다.
      - 보통 전처리 작업 파이프라인(모든 단계가 변환기)일 때  사용
```python
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

order = [
("scaler", StandardScaler()), # 1번째 작업
("svc", SVC(C=0.1, gamma=0.5)), # 2번쨰 작업
]
pipeline = Pipeline(order, verbose=True) # verbose=True: 학습시 로그를 출력
print(pipeline.steps)

# 학습
pipeline.fit(X_train, y_train)
pred_train = pipeline.predict(X_train)
pred_test = pipeline.predict(X_test)
```
- - -
### GridSearch에서 Pipeline 사용
- 하이퍼파라미터 지정시 파이프라인 `프로세스이름__하이퍼파라미터` 형식으로 지정한다.
```python
# SVC: C, gamma
param_grid = {
    "svc__C":[0.001, 0.01, 0, 1, 10, 100],
    "svc__gamma":[0.001, 0.01, 0, 1, 10, 100]
}
grid_search = GridSearchCV(pipeline, # 모델에 pipeline 객체 지정
                          param_grid=param_grid,
                          scoring='accuracy',
                          cv=3,
                          n_jobs=-1)
grid_search.fit(X_train, y_train)
pd.DataFrame(grid_search.cv_results_)
```
- `make_pipeline()`함수로 편리한 파이프라인 생성
```python
from sklearn.pipeline import make_pipeline
pipeline2 = make_pipeline(StandardScaler(), SVC())

# 파이프라인 구성 확인
pipeline2.steps

pipeline2.fit(X_train, y_train)
accuracy_score(y_test, pipeline2.predict(X_test))
```
