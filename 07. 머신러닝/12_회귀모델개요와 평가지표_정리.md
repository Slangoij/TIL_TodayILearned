# 회귀(Regression)
- 지도 학습으로 예측할 Target이 연속형데이터(float)인 경우
- 결정계수. 바이오에선 90%, 공학에선 70%, 사회과학에선 13% 정도가 기준이 된다고 한다.
### 01. 회귀의 주요 평가 지표
- `MSE(Mean Squared Error)`
  - 실제 값과 예측값의 차를 제곱한 후 평균
  - `mean_absolute_error()`, `neg_mean_squared_error`
  ![2021-03-31 18;21;32](https://user-images.githubusercontent.com/71580318/113121797-f7a73680-924d-11eb-8d03-11466eafd371.PNG)
- `RMSE(Root Mean Squared Error)`
  - MSE는 오차의 제곱한 값이므로 실제 오차의 평균보다 큰 값 =>  MSE의 제곱근(= RMSE)
  - scikit-learn은 함수를 지원하지 않는다. (MSE를 구한 뒤 np.sqrt()로 제곱근 구하여 계산)
  ![2021-03-31 18;21;42](https://user-images.githubusercontent.com/71580318/113121809-faa22700-924d-11eb-99cf-27575edd396e.PNG)
- `R^2`(R square, 결정계수)
  - 평균으로 예측 시 오차(총오차)에 대한 모델을 사용 시 성능의 비율
  - 1에 가까울 수록 좋은 모델
  - `r2_score()`, `r2`
  - [참고](https://ko.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/assessing-the-fit-in-least-squares-regression/a/r-squared-intuition)
  ![2021-03-31 18;19;31](https://user-images.githubusercontent.com/71580318/113121492-adbe5080-924d-11eb-8266-a49578c4b7c7.PNG)
  ![2021-03-31 18;20;08](https://user-images.githubusercontent.com/71580318/113121564-bf9ff380-924d-11eb-8960-0c2d348216df.PNG)
```python
# import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_regression
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression

X, y = make_regression(n_samples=100, # 샘플(행)수
                       n_features=1, # feature(컬럼)수 
                       n_informative=1, # target을 만드는데 영향을 주는 feature의 개수.  feature에 영향을 주는 컬럼수
                       noise = 50,   # 잡음
                       coef = False, #Feature간 상관성 여부
                       random_state = 1)
plt.scatter(X, y)

# 학습
lr = LinearRegression()
lr.fit(X, y)

# 예측
pred = lr.predict(X)
from sklearn.metrics import mean_squared_error, r2_score

# 평가
mse = mean_squared_error(y, pred)
r2 = r2_score(y, pred)
print("MSE : ", mse)
print("RMSE : ", np.sqrt(mse))
print('R^2 : ', r2)

score = cross_val_score(lr, X, y, cv=5)#, scoring='r2') #R2
# mse 
cross_val_score(lr, X, y, scoring='neg_mean_squared_error', cv=10) * -1  
#작을 수록 좋은 것인데 양수로 하면 작은게 밑이고 큰게 위이니까 음수로 해서 나오게 함
lr.coef_, lr.intercept_
```
