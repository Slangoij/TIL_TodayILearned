### 02. 학습/테스트 데이터셋 분리
- 테스트를 테스트 데이터셋으로 반복 진행하면 모델이 테스트 데이터셋도
- 학습하므로 중간 점검용 데이터셋은 Validation 데이터셋을 따로 두는 것이 적합
- Validation set 분리 방법

- - -

  ##### 01. Hold Out
  - sklearn.model_selection.train_test_split()  함수 사용
  ```python
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.metrics import accuracy_score
  from sklearn.datasets import load_iris
  from sklearn.model_selection import train_test_split

  # Dataset loading
  iris = load_iris()
  X, y = iris['data'], iris['target']

  # Train, Test Dataset 분리
  X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                     test_size=0.2,
                                                     stratify=y,
                                                     random_state=1)
  # Train, Validation Dataset 분리
  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,
                                                   test_size=0.2,
                                                   stratify=y_train,
                                                    random_state=1)
  y_train.shape, y_val.shape, y_test.shape

  # 모델 생성
  tree = DecisionTreeClassifier(max_depth=2, random_state=1)
  # 하이퍼 파라미터(hyper parameter): 사람이 모델에 직접 설정하는 변수
  # 모델 Train
  tree.fit(X_train, y_train)
  
  # 예측 및 검증 (validation set)
  pred_train = tree.predict(X_train)
  pred_val = tree.predict(X_val)

  acc_train = accuracy_score(y_train, pred_train)
  acc_val = accuracy_score(y_val, pred_val)

  print("Train accuracy:", acc_train)
  print("Validation accuracy:", acc_val)
  
  # test dataset으로 마지막 평가(검증)
  pred_test = tree.predict(X_test)
  acc_test = accuracy_score(y_test, pred_test)
  print('최종 검증결과(test):', acc_test)
  ```


  ##### 02. K-겹 교차검증(K-Fold Cross Validation)
  - 데이터셋을 K개로 분할 후 한 개를 검증세트로 하여 K번 돌아가면서 모든 부분을 검증셋으로 하여 평가지표를 K번을 평균하여 성능 평가
  - 단점: 원 데이터셋에 클래스가 불균형할 가능성 => Stratified K 폴드 기법으로 클래스를 균형화하여 분할
  ```python
  from sklearn.datasets import load_iris
  from sklearn.model_selection import KFold
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.metrics import accuracy_score
  
  iris = load_iris()
  X, y = iris['data'], iris['target']
  
  # 객체를 생성하면서 몇 개의 fold로 나눌지 K값 지정
  kfold = KFold(n_splits=3) # K = 3
  
  acc_train_list = [] # trainset의 평가한 정확도를 저장할 리스트
  acc_test_list = [] # testset으로 평가한 정확도를 저장할 리스트

  for train_index, test_index in kfold.split(X):
    # 데이터셋 분리
    X_train, y_train = X[train_index], y[train_index]
    X_test, y_test = X[test_index], y[test_index]

    # 모델생성
    tree = DecisionTreeClassifier(max_depth=2)
    # 학습
    tree.fit(X_train, y_train)
    # 검증
    pred_train = tree.predict(X_train)
    pred_test = tree.predict(X_test)
    acc_train = accuracy_score(y_train, pred_train)
    acc_test = accuracy_score(y_test, pred_test)
    # 평가결과를 리스트에 추가
    acc_train_list.append(acc_train)
    acc_test_list.append(acc_test)

  import numpy as np
  print("train 정확도:", np.mean(acc_train_list))
  print("test 정확도:", np.mean(acc_test_list))
  ```
  - cross_val_score()
    - 위의 K폴드 기법을 간단히 실행해주는 함수
    - 데이터셋을 K개로 나누고 K번 반복하면서 평가하는 작업을 처리해 주는 함수
    - 주요매개변수
        - estimator: 학습할 평가모델객체
        - X: feature
        - y: label
        - scoring: 평가지표
        - cv: 나눌 개수 (K)
    - 반환값: array - 각 반복마다의 평가점수   
  ```python
  from sklearn.model_selection import cross_val_score
  tree = DecisionTreeClassifier(max_depth=2)
  scores = cross_val_score(estimator=tree,
                         X=X,
                         y=y,
                         scoring='accuracy',
                         cv=3)
                         
  print(scores)
  print(np.round(np.mean(scores),3))
  ```
